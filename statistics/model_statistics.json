{
  "x-ai_grok-4": {
    "true_positives": 16,
    "false_positives": 31,
    "final_score": 0.16666666666666666
  },
  "openai-gpt-4o": {
    "true_positives": 19,
    "false_positives": 37,
    "final_score": 0.18627450980392157
  },
  "nousresearch_hermes-2-pro-llama-3-8b": {
    "true_positives": 19,
    "false_positives": 30,
    "final_score": 0.2
  },
  "openai_gpt-4_1": {
    "true_positives": 15,
    "false_positives": 34,
    "final_score": 0.15151515151515152
  },
  "gpt-4-0125-preview": {
    "true_positives": 14,
    "false_positives": 34,
    "final_score": 0.1414141414141414
  },
  "nousresearch_deephermes-3-llama-3-8b-preview_free": {
    "true_positives": 23,
    "false_positives": 37,
    "final_score": 0.22549019607843138
  },
  "anthropic_claude-opus-4": {
    "true_positives": 11,
    "false_positives": 35,
    "final_score": 0.11
  },
  "meta-llama_llama-4-maverick": {
    "true_positives": 19,
    "false_positives": 39,
    "final_score": 0.18269230769230768
  },
  "mistralai_mistral-7b-instruct_free": {
    "true_positives": 10,
    "false_positives": 47,
    "final_score": 0.08928571428571429
  },
  "mistralai_magistral-medium-2506": {
    "true_positives": 20,
    "false_positives": 40,
    "final_score": 0.19047619047619047
  },
  "deepseek_deepseek-r1-0528-qwen3-8b": {
    "true_positives": 19,
    "false_positives": 39,
    "final_score": 0.18269230769230768
  },
  "anthropic_claude-3_7-sonnet_thinking": {
    "true_positives": 18,
    "false_positives": 33,
    "final_score": 0.1836734693877551
  },
  "gpt-4_1-2025-04-14": {
    "true_positives": 16,
    "false_positives": 33,
    "final_score": 0.16326530612244897
  },
  "google_gemini-2_5-pro": {
    "true_positives": 13,
    "false_positives": 40,
    "final_score": 0.12380952380952381
  }
}